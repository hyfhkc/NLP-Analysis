{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heyifan/anaconda3/lib/python3.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import  display,Image\n",
    "import tensorflow as tf\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>return</th>\n",
       "      <th>vol_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-03</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>41.18</td>\n",
       "      <td>41.9800</td>\n",
       "      <td>40.73</td>\n",
       "      <td>41.93</td>\n",
       "      <td>3089323</td>\n",
       "      <td>0.075125</td>\n",
       "      <td>-0.409335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>41.83</td>\n",
       "      <td>41.9771</td>\n",
       "      <td>40.79</td>\n",
       "      <td>40.93</td>\n",
       "      <td>2541331</td>\n",
       "      <td>0.024432</td>\n",
       "      <td>0.215632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>41.42</td>\n",
       "      <td>41.7400</td>\n",
       "      <td>41.26</td>\n",
       "      <td>41.31</td>\n",
       "      <td>2726213</td>\n",
       "      <td>-0.009199</td>\n",
       "      <td>-0.067816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-06-03</td>\n",
       "      <td>45.65</td>\n",
       "      <td>45.8400</td>\n",
       "      <td>45.04</td>\n",
       "      <td>45.51</td>\n",
       "      <td>3677473</td>\n",
       "      <td>-0.092287</td>\n",
       "      <td>-0.258672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>43.05</td>\n",
       "      <td>43.7700</td>\n",
       "      <td>42.91</td>\n",
       "      <td>43.59</td>\n",
       "      <td>4283821</td>\n",
       "      <td>0.044047</td>\n",
       "      <td>-0.141544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name        date   open     high    low  close   volume    return  \\\n",
       "index                                                                       \n",
       "2013-03    A  2013-03-01  41.18  41.9800  40.73  41.93  3089323  0.075125   \n",
       "2013-04    A  2013-04-01  41.83  41.9771  40.79  40.93  2541331  0.024432   \n",
       "2013-05    A  2013-05-01  41.42  41.7400  41.26  41.31  2726213 -0.009199   \n",
       "2013-06    A  2013-06-03  45.65  45.8400  45.04  45.51  3677473 -0.092287   \n",
       "2013-07    A  2013-07-01  43.05  43.7700  42.91  43.59  4283821  0.044047   \n",
       "\n",
       "         vol_change  \n",
       "index                \n",
       "2013-03   -0.409335  \n",
       "2013-04    0.215632  \n",
       "2013-05   -0.067816  \n",
       "2013-06   -0.258672  \n",
       "2013-07   -0.141544  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/heyifan/jupyter notebook/df_featured.csv\", index_col = \"index\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 Data engineering\n",
    "Take one stock as example\n",
    "\n",
    "先根据return来提取feature \n",
    "\n",
    "根据过去11个月的return来预测下一个月的return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape for stock A: (60, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>return</th>\n",
       "      <th>vol_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-03</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>41.18</td>\n",
       "      <td>41.9800</td>\n",
       "      <td>40.730</td>\n",
       "      <td>41.93</td>\n",
       "      <td>3089323</td>\n",
       "      <td>0.075125</td>\n",
       "      <td>-0.409335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>41.83</td>\n",
       "      <td>41.9771</td>\n",
       "      <td>40.790</td>\n",
       "      <td>40.93</td>\n",
       "      <td>2541331</td>\n",
       "      <td>0.024432</td>\n",
       "      <td>0.215632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>41.42</td>\n",
       "      <td>41.7400</td>\n",
       "      <td>41.260</td>\n",
       "      <td>41.31</td>\n",
       "      <td>2726213</td>\n",
       "      <td>-0.009199</td>\n",
       "      <td>-0.067816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-06-03</td>\n",
       "      <td>45.65</td>\n",
       "      <td>45.8400</td>\n",
       "      <td>45.040</td>\n",
       "      <td>45.51</td>\n",
       "      <td>3677473</td>\n",
       "      <td>-0.092287</td>\n",
       "      <td>-0.258672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>43.05</td>\n",
       "      <td>43.7700</td>\n",
       "      <td>42.910</td>\n",
       "      <td>43.59</td>\n",
       "      <td>4283821</td>\n",
       "      <td>0.044047</td>\n",
       "      <td>-0.141544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-08-01</td>\n",
       "      <td>45.51</td>\n",
       "      <td>46.2000</td>\n",
       "      <td>45.320</td>\n",
       "      <td>46.04</td>\n",
       "      <td>2745041</td>\n",
       "      <td>-0.053215</td>\n",
       "      <td>0.560567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-09-03</td>\n",
       "      <td>47.04</td>\n",
       "      <td>47.5100</td>\n",
       "      <td>46.615</td>\n",
       "      <td>46.93</td>\n",
       "      <td>1565632</td>\n",
       "      <td>-0.018964</td>\n",
       "      <td>0.753312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>50.70</td>\n",
       "      <td>52.0800</td>\n",
       "      <td>50.700</td>\n",
       "      <td>51.90</td>\n",
       "      <td>2997047</td>\n",
       "      <td>-0.095761</td>\n",
       "      <td>-0.477608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-11-01</td>\n",
       "      <td>50.92</td>\n",
       "      <td>51.5800</td>\n",
       "      <td>50.840</td>\n",
       "      <td>51.10</td>\n",
       "      <td>1931035</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.552042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-12-02</td>\n",
       "      <td>53.47</td>\n",
       "      <td>53.6700</td>\n",
       "      <td>53.110</td>\n",
       "      <td>53.21</td>\n",
       "      <td>1459197</td>\n",
       "      <td>-0.039654</td>\n",
       "      <td>0.323355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01</th>\n",
       "      <td>A</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>57.10</td>\n",
       "      <td>57.1000</td>\n",
       "      <td>56.150</td>\n",
       "      <td>56.21</td>\n",
       "      <td>1916160</td>\n",
       "      <td>-0.053371</td>\n",
       "      <td>-0.238479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02</th>\n",
       "      <td>A</td>\n",
       "      <td>2014-02-03</td>\n",
       "      <td>58.15</td>\n",
       "      <td>58.4800</td>\n",
       "      <td>56.075</td>\n",
       "      <td>56.15</td>\n",
       "      <td>2929252</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>-0.345853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03</th>\n",
       "      <td>A</td>\n",
       "      <td>2014-03-03</td>\n",
       "      <td>56.12</td>\n",
       "      <td>57.1200</td>\n",
       "      <td>55.785</td>\n",
       "      <td>56.71</td>\n",
       "      <td>2488373</td>\n",
       "      <td>-0.009875</td>\n",
       "      <td>0.177176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04</th>\n",
       "      <td>A</td>\n",
       "      <td>2014-04-01</td>\n",
       "      <td>56.20</td>\n",
       "      <td>56.6200</td>\n",
       "      <td>55.835</td>\n",
       "      <td>56.36</td>\n",
       "      <td>2090720</td>\n",
       "      <td>0.006210</td>\n",
       "      <td>0.190199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05</th>\n",
       "      <td>A</td>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>53.94</td>\n",
       "      <td>54.8700</td>\n",
       "      <td>53.660</td>\n",
       "      <td>54.47</td>\n",
       "      <td>1472407</td>\n",
       "      <td>0.034698</td>\n",
       "      <td>0.419933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06</th>\n",
       "      <td>A</td>\n",
       "      <td>2014-06-02</td>\n",
       "      <td>56.96</td>\n",
       "      <td>56.9900</td>\n",
       "      <td>56.300</td>\n",
       "      <td>56.89</td>\n",
       "      <td>1274846</td>\n",
       "      <td>-0.042538</td>\n",
       "      <td>0.154969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07</th>\n",
       "      <td>A</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>57.74</td>\n",
       "      <td>58.4400</td>\n",
       "      <td>57.380</td>\n",
       "      <td>58.25</td>\n",
       "      <td>2010785</td>\n",
       "      <td>-0.023348</td>\n",
       "      <td>-0.365996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08</th>\n",
       "      <td>A</td>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>56.19</td>\n",
       "      <td>56.4000</td>\n",
       "      <td>55.590</td>\n",
       "      <td>56.26</td>\n",
       "      <td>957560</td>\n",
       "      <td>0.035371</td>\n",
       "      <td>1.099905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09</th>\n",
       "      <td>A</td>\n",
       "      <td>2014-09-02</td>\n",
       "      <td>57.23</td>\n",
       "      <td>58.1000</td>\n",
       "      <td>57.230</td>\n",
       "      <td>58.07</td>\n",
       "      <td>2015566</td>\n",
       "      <td>-0.031169</td>\n",
       "      <td>-0.524918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-10</th>\n",
       "      <td>A</td>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>56.85</td>\n",
       "      <td>56.9300</td>\n",
       "      <td>56.180</td>\n",
       "      <td>56.20</td>\n",
       "      <td>2481276</td>\n",
       "      <td>0.033274</td>\n",
       "      <td>-0.187690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name        date   open     high     low  close   volume    return  \\\n",
       "index                                                                        \n",
       "2013-03    A  2013-03-01  41.18  41.9800  40.730  41.93  3089323  0.075125   \n",
       "2013-04    A  2013-04-01  41.83  41.9771  40.790  40.93  2541331  0.024432   \n",
       "2013-05    A  2013-05-01  41.42  41.7400  41.260  41.31  2726213 -0.009199   \n",
       "2013-06    A  2013-06-03  45.65  45.8400  45.040  45.51  3677473 -0.092287   \n",
       "2013-07    A  2013-07-01  43.05  43.7700  42.910  43.59  4283821  0.044047   \n",
       "2013-08    A  2013-08-01  45.51  46.2000  45.320  46.04  2745041 -0.053215   \n",
       "2013-09    A  2013-09-03  47.04  47.5100  46.615  46.93  1565632 -0.018964   \n",
       "2013-10    A  2013-10-01  50.70  52.0800  50.700  51.90  2997047 -0.095761   \n",
       "2013-11    A  2013-11-01  50.92  51.5800  50.840  51.10  1931035  0.015656   \n",
       "2013-12    A  2013-12-02  53.47  53.6700  53.110  53.21  1459197 -0.039654   \n",
       "2014-01    A  2014-01-02  57.10  57.1000  56.150  56.21  1916160 -0.053371   \n",
       "2014-02    A  2014-02-03  58.15  58.4800  56.075  56.15  2929252  0.001069   \n",
       "2014-03    A  2014-03-03  56.12  57.1200  55.785  56.71  2488373 -0.009875   \n",
       "2014-04    A  2014-04-01  56.20  56.6200  55.835  56.36  2090720  0.006210   \n",
       "2014-05    A  2014-05-01  53.94  54.8700  53.660  54.47  1472407  0.034698   \n",
       "2014-06    A  2014-06-02  56.96  56.9900  56.300  56.89  1274846 -0.042538   \n",
       "2014-07    A  2014-07-01  57.74  58.4400  57.380  58.25  2010785 -0.023348   \n",
       "2014-08    A  2014-08-01  56.19  56.4000  55.590  56.26   957560  0.035371   \n",
       "2014-09    A  2014-09-02  57.23  58.1000  57.230  58.07  2015566 -0.031169   \n",
       "2014-10    A  2014-10-01  56.85  56.9300  56.180  56.20  2481276  0.033274   \n",
       "\n",
       "         vol_change  \n",
       "index                \n",
       "2013-03   -0.409335  \n",
       "2013-04    0.215632  \n",
       "2013-05   -0.067816  \n",
       "2013-06   -0.258672  \n",
       "2013-07   -0.141544  \n",
       "2013-08    0.560567  \n",
       "2013-09    0.753312  \n",
       "2013-10   -0.477608  \n",
       "2013-11    0.552042  \n",
       "2013-12    0.323355  \n",
       "2014-01   -0.238479  \n",
       "2014-02   -0.345853  \n",
       "2014-03    0.177176  \n",
       "2014-04    0.190199  \n",
       "2014-05    0.419933  \n",
       "2014-06    0.154969  \n",
       "2014-07   -0.365996  \n",
       "2014-08    1.099905  \n",
       "2014-09   -0.524918  \n",
       "2014-10   -0.187690  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = df[df[\"Name\"] == \"A\"]\n",
    "print(f\"shape for stock A: {A.shape}\")\n",
    "A.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rolling window的概念：https://blog.csdn.net/maymay_/article/details/80241627"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_process(df,rollSize=12):\n",
    "    if df.shape[0] < rollSize: # 如果股票的数据不足12个月则剔除这只股票 \n",
    "        return None\n",
    "    else:\n",
    "        train_x = []\n",
    "        train_y = []\n",
    "        for i in range(df.shape[0]-rollSize):\n",
    "            x = df[['return','vol_change']][i:i+rollSize-1].values.tolist()  ### x就是以12个月为单位的rolling取值；x[1]：第一组12个月的值，x[2]：第二组12个月的值\n",
    "            y = df['return'][i+rollSize]  ### y是return率取完一个rolling window后下一个值 \n",
    "\n",
    "            train_x.append(x)\n",
    "            train_y.append([y])\n",
    "        return train_x,train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X data generated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[0.07512520868113515, -0.40933499022277703],\n",
       "  [0.024431956999755755, 0.21563188738499628],\n",
       "  [-0.009198741224885064, -0.06781641786610215],\n",
       "  [-0.09228740936058, -0.25867219147496123],\n",
       "  [0.044046799724707375, -0.14154372930148107],\n",
       "  [-0.05321459600347511, 0.5605672192145763],\n",
       "  [-0.018964415086298758, 0.7533117616400278],\n",
       "  [-0.09576107899807318, -0.477608459260065],\n",
       "  [0.015655577299412915, 0.5520417807030944],\n",
       "  [-0.03965420033828226, 0.3233545573353016],\n",
       "  [-0.05337128624799858, -0.23847851953907814]],\n",
       " [[0.024431956999755755, 0.21563188738499628],\n",
       "  [-0.009198741224885064, -0.06781641786610215],\n",
       "  [-0.09228740936058, -0.25867219147496123],\n",
       "  [0.044046799724707375, -0.14154372930148107],\n",
       "  [-0.05321459600347511, 0.5605672192145763],\n",
       "  [-0.018964415086298758, 0.7533117616400278],\n",
       "  [-0.09576107899807318, -0.477608459260065],\n",
       "  [0.015655577299412915, 0.5520417807030944],\n",
       "  [-0.03965420033828226, 0.3233545573353016],\n",
       "  [-0.05337128624799858, -0.23847851953907814],\n",
       "  [0.0010685663401603929, -0.34585348068380595]],\n",
       " [[-0.009198741224885064, -0.06781641786610215],\n",
       "  [-0.09228740936058, -0.25867219147496123],\n",
       "  [0.044046799724707375, -0.14154372930148107],\n",
       "  [-0.05321459600347511, 0.5605672192145763],\n",
       "  [-0.018964415086298758, 0.7533117616400278],\n",
       "  [-0.09576107899807318, -0.477608459260065],\n",
       "  [0.015655577299412915, 0.5520417807030944],\n",
       "  [-0.03965420033828226, 0.3233545573353016],\n",
       "  [-0.05337128624799858, -0.23847851953907814],\n",
       "  [0.0010685663401603929, -0.34585348068380595],\n",
       "  [-0.009874801622288931, 0.1771756083191709]]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"X data generated\")\n",
    "cnn_process(A)[0][:3] # a股票的前三组rolling取值 第一列为return；第二列为vol_change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 因为rolling window为12，所以头12支股票是没有办法取rolling组的；一共有60支股票，所以一共只有60-12=48个rolling组 \n",
    "len( cnn_process(A)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y data generated:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[-0.009874801622288931], [0.006210078069552871], [0.034697998898476134]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Y data generated:\")\n",
    "cnn_process(A)[1][:3] # cnn_process[0]表示rolling window；cnn_process[1]表示所有y的取值；仅为return的值 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby & apply to all stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_Y = df.groupby('Name').apply(lambda x: cnn_process(x,rollSize=12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name\n",
       "A       ([[[0.07512520868113515, -0.40933499022277703]...\n",
       "AAL     ([[[0.08376193975018363, 0.13972183060405596],...\n",
       "AAP     ([[[0.033128191698310834, 0.02004755528734337]...\n",
       "AAPL    ([[[0.10339747331927283, 0.14698706280343174],...\n",
       "ABBV    ([[[-0.04125892620999738, 0.5520446606645322],...\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_x = []\n",
    "raw_y = []\n",
    "ID_2_stock = {}\n",
    "for ID in range(len(df_X_Y.values)):\n",
    "    if df_X_Y.values[ID]: ## not none\n",
    "        stock = df_X_Y.index.values[ID]\n",
    "        ID_2_stock.update({ID:stock})\n",
    "        stockData = df_X_Y[stock]\n",
    "        raw_x.append(stockData[0])\n",
    "        raw_y.append(stockData[1])\n",
    "x = np.vstack(raw_x)\n",
    "y = np.vstack(raw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'A',\n",
       " 1: 'AAL',\n",
       " 2: 'AAP',\n",
       " 3: 'AAPL',\n",
       " 4: 'ABBV',\n",
       " 5: 'ABC',\n",
       " 6: 'ABT',\n",
       " 7: 'ACN',\n",
       " 8: 'ADBE',\n",
       " 9: 'ADI',\n",
       " 10: 'ADM',\n",
       " 11: 'ADP',\n",
       " 12: 'ADS',\n",
       " 13: 'ADSK',\n",
       " 14: 'AEE',\n",
       " 15: 'AEP',\n",
       " 16: 'AES',\n",
       " 17: 'AET',\n",
       " 18: 'AFL',\n",
       " 19: 'AGN',\n",
       " 20: 'AIG',\n",
       " 21: 'AIV',\n",
       " 22: 'AIZ',\n",
       " 23: 'AJG',\n",
       " 24: 'AKAM',\n",
       " 25: 'ALB',\n",
       " 26: 'ALGN',\n",
       " 27: 'ALK',\n",
       " 28: 'ALL',\n",
       " 29: 'ALLE',\n",
       " 30: 'ALXN',\n",
       " 31: 'AMAT',\n",
       " 32: 'AMD',\n",
       " 33: 'AME',\n",
       " 34: 'AMG',\n",
       " 35: 'AMGN',\n",
       " 36: 'AMP',\n",
       " 37: 'AMT',\n",
       " 38: 'AMZN',\n",
       " 39: 'ANDV',\n",
       " 40: 'ANSS',\n",
       " 41: 'ANTM',\n",
       " 42: 'AON',\n",
       " 43: 'AOS',\n",
       " 44: 'APA',\n",
       " 45: 'APC',\n",
       " 46: 'APD',\n",
       " 47: 'APH',\n",
       " 49: 'ARE',\n",
       " 50: 'ARNC',\n",
       " 51: 'ATVI',\n",
       " 52: 'AVB',\n",
       " 53: 'AVGO',\n",
       " 54: 'AVY',\n",
       " 55: 'AWK',\n",
       " 56: 'AXP',\n",
       " 57: 'AYI',\n",
       " 58: 'AZO',\n",
       " 59: 'BA',\n",
       " 60: 'BAC',\n",
       " 61: 'BAX',\n",
       " 62: 'BBT',\n",
       " 63: 'BBY',\n",
       " 64: 'BDX',\n",
       " 65: 'BEN',\n",
       " 66: 'BF.B',\n",
       " 69: 'BIIB',\n",
       " 70: 'BK',\n",
       " 71: 'BLK',\n",
       " 72: 'BLL',\n",
       " 73: 'BMY',\n",
       " 74: 'BRK.B',\n",
       " 75: 'BSX',\n",
       " 76: 'BWA',\n",
       " 77: 'BXP',\n",
       " 78: 'C',\n",
       " 79: 'CA',\n",
       " 80: 'CAG',\n",
       " 81: 'CAH',\n",
       " 82: 'CAT',\n",
       " 83: 'CB',\n",
       " 84: 'CBG',\n",
       " 85: 'CBOE',\n",
       " 86: 'CBS',\n",
       " 87: 'CCI',\n",
       " 88: 'CCL',\n",
       " 89: 'CDNS',\n",
       " 90: 'CELG',\n",
       " 91: 'CERN',\n",
       " 92: 'CF',\n",
       " 93: 'CFG',\n",
       " 94: 'CHD',\n",
       " 95: 'CHK',\n",
       " 96: 'CHRW',\n",
       " 97: 'CHTR',\n",
       " 98: 'CI',\n",
       " 99: 'CINF',\n",
       " 100: 'CL',\n",
       " 101: 'CLX',\n",
       " 102: 'CMA',\n",
       " 103: 'CMCSA',\n",
       " 104: 'CME',\n",
       " 105: 'CMG',\n",
       " 106: 'CMI',\n",
       " 107: 'CMS',\n",
       " 108: 'CNC',\n",
       " 109: 'CNP',\n",
       " 110: 'COF',\n",
       " 111: 'COG',\n",
       " 112: 'COL',\n",
       " 113: 'COO',\n",
       " 114: 'COP',\n",
       " 115: 'COST',\n",
       " 116: 'COTY',\n",
       " 117: 'CPB',\n",
       " 118: 'CRM',\n",
       " 119: 'CSCO',\n",
       " 120: 'CSRA',\n",
       " 121: 'CSX',\n",
       " 122: 'CTAS',\n",
       " 123: 'CTL',\n",
       " 124: 'CTSH',\n",
       " 125: 'CTXS',\n",
       " 126: 'CVS',\n",
       " 127: 'CVX',\n",
       " 128: 'CXO',\n",
       " 129: 'D',\n",
       " 130: 'DAL',\n",
       " 131: 'DE',\n",
       " 132: 'DFS',\n",
       " 133: 'DG',\n",
       " 134: 'DGX',\n",
       " 135: 'DHI',\n",
       " 136: 'DHR',\n",
       " 137: 'DIS',\n",
       " 138: 'DISCA',\n",
       " 139: 'DISCK',\n",
       " 140: 'DISH',\n",
       " 141: 'DLR',\n",
       " 142: 'DLTR',\n",
       " 143: 'DOV',\n",
       " 144: 'DPS',\n",
       " 145: 'DRE',\n",
       " 146: 'DRI',\n",
       " 147: 'DTE',\n",
       " 148: 'DUK',\n",
       " 149: 'DVA',\n",
       " 150: 'DVN',\n",
       " 153: 'EA',\n",
       " 154: 'EBAY',\n",
       " 155: 'ECL',\n",
       " 156: 'ED',\n",
       " 157: 'EFX',\n",
       " 158: 'EIX',\n",
       " 159: 'EL',\n",
       " 160: 'EMN',\n",
       " 161: 'EMR',\n",
       " 162: 'EOG',\n",
       " 163: 'EQIX',\n",
       " 164: 'EQR',\n",
       " 165: 'EQT',\n",
       " 166: 'ES',\n",
       " 167: 'ESRX',\n",
       " 168: 'ESS',\n",
       " 169: 'ETFC',\n",
       " 170: 'ETN',\n",
       " 171: 'ETR',\n",
       " 172: 'EVHC',\n",
       " 173: 'EW',\n",
       " 174: 'EXC',\n",
       " 175: 'EXPD',\n",
       " 176: 'EXPE',\n",
       " 177: 'EXR',\n",
       " 178: 'F',\n",
       " 179: 'FAST',\n",
       " 180: 'FB',\n",
       " 181: 'FBHS',\n",
       " 182: 'FCX',\n",
       " 183: 'FDX',\n",
       " 184: 'FE',\n",
       " 185: 'FFIV',\n",
       " 186: 'FIS',\n",
       " 187: 'FISV',\n",
       " 188: 'FITB',\n",
       " 189: 'FL',\n",
       " 190: 'FLIR',\n",
       " 191: 'FLR',\n",
       " 192: 'FLS',\n",
       " 193: 'FMC',\n",
       " 194: 'FOX',\n",
       " 195: 'FOXA',\n",
       " 196: 'FRT',\n",
       " 197: 'FTI',\n",
       " 198: 'FTV',\n",
       " 199: 'GD',\n",
       " 200: 'GE',\n",
       " 201: 'GGP',\n",
       " 202: 'GILD',\n",
       " 203: 'GIS',\n",
       " 204: 'GLW',\n",
       " 205: 'GM',\n",
       " 206: 'GOOG',\n",
       " 207: 'GOOGL',\n",
       " 208: 'GPC',\n",
       " 209: 'GPN',\n",
       " 210: 'GPS',\n",
       " 211: 'GRMN',\n",
       " 212: 'GS',\n",
       " 213: 'GT',\n",
       " 214: 'GWW',\n",
       " 215: 'HAL',\n",
       " 216: 'HAS',\n",
       " 217: 'HBAN',\n",
       " 218: 'HBI',\n",
       " 219: 'HCA',\n",
       " 220: 'HCN',\n",
       " 221: 'HCP',\n",
       " 222: 'HD',\n",
       " 223: 'HES',\n",
       " 224: 'HIG',\n",
       " 225: 'HII',\n",
       " 226: 'HLT',\n",
       " 227: 'HOG',\n",
       " 228: 'HOLX',\n",
       " 229: 'HON',\n",
       " 230: 'HP',\n",
       " 231: 'HPE',\n",
       " 232: 'HPQ',\n",
       " 233: 'HRB',\n",
       " 234: 'HRL',\n",
       " 235: 'HRS',\n",
       " 236: 'HSIC',\n",
       " 237: 'HST',\n",
       " 238: 'HSY',\n",
       " 239: 'HUM',\n",
       " 240: 'IBM',\n",
       " 241: 'ICE',\n",
       " 242: 'IDXX',\n",
       " 243: 'IFF',\n",
       " 244: 'ILMN',\n",
       " 245: 'INCY',\n",
       " 246: 'INFO',\n",
       " 247: 'INTC',\n",
       " 248: 'INTU',\n",
       " 249: 'IP',\n",
       " 250: 'IPG',\n",
       " 251: 'IQV',\n",
       " 252: 'IR',\n",
       " 253: 'IRM',\n",
       " 254: 'ISRG',\n",
       " 255: 'IT',\n",
       " 256: 'ITW',\n",
       " 257: 'IVZ',\n",
       " 258: 'JBHT',\n",
       " 259: 'JCI',\n",
       " 260: 'JEC',\n",
       " 261: 'JNJ',\n",
       " 262: 'JNPR',\n",
       " 263: 'JPM',\n",
       " 264: 'JWN',\n",
       " 265: 'K',\n",
       " 266: 'KEY',\n",
       " 267: 'KHC',\n",
       " 268: 'KIM',\n",
       " 269: 'KLAC',\n",
       " 270: 'KMB',\n",
       " 271: 'KMI',\n",
       " 272: 'KMX',\n",
       " 273: 'KO',\n",
       " 274: 'KORS',\n",
       " 275: 'KR',\n",
       " 276: 'KSS',\n",
       " 277: 'KSU',\n",
       " 278: 'L',\n",
       " 279: 'LB',\n",
       " 280: 'LEG',\n",
       " 281: 'LEN',\n",
       " 282: 'LH',\n",
       " 283: 'LKQ',\n",
       " 284: 'LLL',\n",
       " 285: 'LLY',\n",
       " 286: 'LMT',\n",
       " 287: 'LNC',\n",
       " 288: 'LNT',\n",
       " 289: 'LOW',\n",
       " 290: 'LRCX',\n",
       " 291: 'LUK',\n",
       " 292: 'LUV',\n",
       " 293: 'LYB',\n",
       " 294: 'M',\n",
       " 295: 'MA',\n",
       " 296: 'MAA',\n",
       " 297: 'MAC',\n",
       " 298: 'MAR',\n",
       " 299: 'MAS',\n",
       " 300: 'MAT',\n",
       " 301: 'MCD',\n",
       " 302: 'MCHP',\n",
       " 303: 'MCK',\n",
       " 304: 'MCO',\n",
       " 305: 'MDLZ',\n",
       " 306: 'MDT',\n",
       " 307: 'MET',\n",
       " 308: 'MGM',\n",
       " 309: 'MHK',\n",
       " 310: 'MKC',\n",
       " 311: 'MLM',\n",
       " 312: 'MMC',\n",
       " 313: 'MMM',\n",
       " 314: 'MNST',\n",
       " 315: 'MO',\n",
       " 316: 'MON',\n",
       " 317: 'MOS',\n",
       " 318: 'MPC',\n",
       " 319: 'MRK',\n",
       " 320: 'MRO',\n",
       " 321: 'MS',\n",
       " 322: 'MSFT',\n",
       " 323: 'MSI',\n",
       " 324: 'MTB',\n",
       " 325: 'MTD',\n",
       " 326: 'MU',\n",
       " 327: 'MYL',\n",
       " 328: 'NAVI',\n",
       " 329: 'NBL',\n",
       " 330: 'NCLH',\n",
       " 331: 'NDAQ',\n",
       " 332: 'NEE',\n",
       " 333: 'NEM',\n",
       " 334: 'NFLX',\n",
       " 335: 'NFX',\n",
       " 336: 'NI',\n",
       " 337: 'NKE',\n",
       " 338: 'NLSN',\n",
       " 339: 'NOC',\n",
       " 340: 'NOV',\n",
       " 341: 'NRG',\n",
       " 342: 'NSC',\n",
       " 343: 'NTAP',\n",
       " 344: 'NTRS',\n",
       " 345: 'NUE',\n",
       " 346: 'NVDA',\n",
       " 347: 'NWL',\n",
       " 348: 'NWS',\n",
       " 349: 'NWSA',\n",
       " 350: 'O',\n",
       " 351: 'OKE',\n",
       " 352: 'OMC',\n",
       " 353: 'ORCL',\n",
       " 354: 'ORLY',\n",
       " 355: 'OXY',\n",
       " 356: 'PAYX',\n",
       " 357: 'PBCT',\n",
       " 358: 'PCAR',\n",
       " 359: 'PCG',\n",
       " 360: 'PCLN',\n",
       " 361: 'PDCO',\n",
       " 362: 'PEG',\n",
       " 363: 'PEP',\n",
       " 364: 'PFE',\n",
       " 365: 'PFG',\n",
       " 366: 'PG',\n",
       " 367: 'PGR',\n",
       " 368: 'PH',\n",
       " 369: 'PHM',\n",
       " 370: 'PKG',\n",
       " 371: 'PKI',\n",
       " 372: 'PLD',\n",
       " 373: 'PM',\n",
       " 374: 'PNC',\n",
       " 375: 'PNR',\n",
       " 376: 'PNW',\n",
       " 377: 'PPG',\n",
       " 378: 'PPL',\n",
       " 379: 'PRGO',\n",
       " 380: 'PRU',\n",
       " 381: 'PSA',\n",
       " 382: 'PSX',\n",
       " 383: 'PVH',\n",
       " 384: 'PWR',\n",
       " 385: 'PX',\n",
       " 386: 'PXD',\n",
       " 387: 'PYPL',\n",
       " 388: 'QCOM',\n",
       " 389: 'QRVO',\n",
       " 390: 'RCL',\n",
       " 391: 'RE',\n",
       " 392: 'REG',\n",
       " 393: 'REGN',\n",
       " 394: 'RF',\n",
       " 395: 'RHI',\n",
       " 396: 'RHT',\n",
       " 397: 'RJF',\n",
       " 398: 'RL',\n",
       " 399: 'RMD',\n",
       " 400: 'ROK',\n",
       " 401: 'ROP',\n",
       " 402: 'ROST',\n",
       " 403: 'RRC',\n",
       " 404: 'RSG',\n",
       " 405: 'RTN',\n",
       " 406: 'SBAC',\n",
       " 407: 'SBUX',\n",
       " 408: 'SCG',\n",
       " 409: 'SCHW',\n",
       " 410: 'SEE',\n",
       " 411: 'SHW',\n",
       " 412: 'SIG',\n",
       " 413: 'SJM',\n",
       " 414: 'SLB',\n",
       " 415: 'SLG',\n",
       " 416: 'SNA',\n",
       " 417: 'SNI',\n",
       " 418: 'SNPS',\n",
       " 419: 'SO',\n",
       " 420: 'SPG',\n",
       " 421: 'SPGI',\n",
       " 422: 'SRCL',\n",
       " 423: 'SRE',\n",
       " 424: 'STI',\n",
       " 425: 'STT',\n",
       " 426: 'STX',\n",
       " 427: 'STZ',\n",
       " 428: 'SWK',\n",
       " 429: 'SWKS',\n",
       " 430: 'SYF',\n",
       " 431: 'SYK',\n",
       " 432: 'SYMC',\n",
       " 433: 'SYY',\n",
       " 434: 'T',\n",
       " 435: 'TAP',\n",
       " 436: 'TDG',\n",
       " 437: 'TEL',\n",
       " 438: 'TGT',\n",
       " 439: 'TIF',\n",
       " 440: 'TJX',\n",
       " 441: 'TMK',\n",
       " 442: 'TMO',\n",
       " 443: 'TPR',\n",
       " 444: 'TRIP',\n",
       " 445: 'TROW',\n",
       " 446: 'TRV',\n",
       " 447: 'TSCO',\n",
       " 448: 'TSN',\n",
       " 449: 'TSS',\n",
       " 450: 'TWX',\n",
       " 451: 'TXN',\n",
       " 452: 'TXT',\n",
       " 453: 'UA',\n",
       " 454: 'UAA',\n",
       " 455: 'UAL',\n",
       " 456: 'UDR',\n",
       " 457: 'UHS',\n",
       " 458: 'ULTA',\n",
       " 459: 'UNH',\n",
       " 460: 'UNM',\n",
       " 461: 'UNP',\n",
       " 462: 'UPS',\n",
       " 463: 'URI',\n",
       " 464: 'USB',\n",
       " 465: 'UTX',\n",
       " 466: 'V',\n",
       " 467: 'VAR',\n",
       " 468: 'VFC',\n",
       " 469: 'VIAB',\n",
       " 470: 'VLO',\n",
       " 471: 'VMC',\n",
       " 472: 'VNO',\n",
       " 473: 'VRSK',\n",
       " 474: 'VRSN',\n",
       " 475: 'VRTX',\n",
       " 476: 'VTR',\n",
       " 477: 'VZ',\n",
       " 478: 'WAT',\n",
       " 479: 'WBA',\n",
       " 480: 'WDC',\n",
       " 481: 'WEC',\n",
       " 482: 'WFC',\n",
       " 483: 'WHR',\n",
       " 484: 'WLTW',\n",
       " 485: 'WM',\n",
       " 486: 'WMB',\n",
       " 487: 'WMT',\n",
       " 488: 'WRK',\n",
       " 489: 'WU',\n",
       " 490: 'WY',\n",
       " 491: 'WYN',\n",
       " 492: 'WYNN',\n",
       " 493: 'XEC',\n",
       " 494: 'XEL',\n",
       " 495: 'XL',\n",
       " 496: 'XLNX',\n",
       " 497: 'XOM',\n",
       " 498: 'XRAY',\n",
       " 499: 'XRX',\n",
       " 500: 'XYL',\n",
       " 501: 'YUM',\n",
       " 502: 'ZBH',\n",
       " 503: 'ZION',\n",
       " 504: 'ZTS'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_2_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ID_2_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.07512521, -0.40933499],\n",
       "        [ 0.02443196,  0.21563189],\n",
       "        [-0.00919874, -0.06781642],\n",
       "        ...,\n",
       "        [ 0.01565558,  0.55204178],\n",
       "        [-0.0396542 ,  0.32335456],\n",
       "        [-0.05337129, -0.23847852]],\n",
       "\n",
       "       [[ 0.02443196,  0.21563189],\n",
       "        [-0.00919874, -0.06781642],\n",
       "        [-0.09228741, -0.25867219],\n",
       "        ...,\n",
       "        [-0.0396542 ,  0.32335456],\n",
       "        [-0.05337129, -0.23847852],\n",
       "        [ 0.00106857, -0.34585348]],\n",
       "\n",
       "       [[-0.00919874, -0.06781642],\n",
       "        [-0.09228741, -0.25867219],\n",
       "        [ 0.0440468 , -0.14154373],\n",
       "        ...,\n",
       "        [-0.05337129, -0.23847852],\n",
       "        [ 0.00106857, -0.34585348],\n",
       "        [-0.0098748 ,  0.17717561]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.03885273,  1.05128844],\n",
       "        [-0.08266468,  0.1876882 ],\n",
       "        [-0.0312726 ,  0.4366541 ],\n",
       "        ...,\n",
       "        [ 0.00885383, -0.41742659],\n",
       "        [-0.01192938, -0.09235378],\n",
       "        [-0.01380392, -0.23442479]],\n",
       "\n",
       "       [[-0.08266468,  0.1876882 ],\n",
       "        [-0.0312726 ,  0.4366541 ],\n",
       "        [ 0.02653554, -0.30407662],\n",
       "        ...,\n",
       "        [-0.01192938, -0.09235378],\n",
       "        [-0.01380392, -0.23442479],\n",
       "        [-0.01178112, -0.40034058]],\n",
       "\n",
       "       [[-0.0312726 ,  0.4366541 ],\n",
       "        [ 0.02653554, -0.30407662],\n",
       "        [ 0.01354147,  0.27601446],\n",
       "        ...,\n",
       "        [-0.01380392, -0.23442479],\n",
       "        [-0.01178112, -0.40034058],\n",
       "        [-0.1077455 ,  0.58673715]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23476, 11, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape # 一共抽取出多于12个月历史记录的股票500支，每支股票都有48个rolling window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23476, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Modeling\n",
    "## Part 3.1 Product feature extraction based on CNN model with 1 feature(\"return\")\n",
    "### Part 3.1.1 Define some default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 2 ### number of features, here we are using return & volatility\n",
    "n_outputs = 1 ### number of outputs, here we only care the next month(step) return\n",
    "n_timesteps = 11 ### number of months look back, here we are using 12 - 1 = 11\n",
    "verbose = 1 ### how model training progress bar will show # print的方式 \n",
    "epochs = 100 \n",
    "batch_size =  2000 ### batch training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.1.2 Build CNN models based on \"return\" features <br>\n",
    "#### The output layer will be the prediction of  next month return based on last n months, so the last layer [latent1, latent2, latent3,...] will be the feature that predict the return, so we could use it as stock features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23476, 11)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,:,0].shape # 这样操作会少一个dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_1 shape: (23476, 11, 1)\n"
     ]
    }
   ],
   "source": [
    "x_1 = x[:,:,0]  ### x_1 will lose 1 dim, since shape of x is (23476, 11, 2), so we need to reshape it to be (23476, 11, 1) 这里我们只使用return作为feature进行预测\n",
    "x_1 = np.expand_dims(x_1,2) # 通过该操作来保存矩阵维度的完整 \n",
    "print(f\"x_1 shape: {x_1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/heyifan/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/heyifan/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 18780 samples, validate on 4696 samples\n",
      "Epoch 1/500\n",
      "18780/18780 [==============================] - 0s 15us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 2/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 3/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 4/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 5/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 6/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 7/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 8/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 9/500\n",
      "18780/18780 [==============================] - 0s 3us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 10/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 11/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 12/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 13/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 14/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 15/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 16/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 17/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 18/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 19/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 20/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 21/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 22/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 23/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 24/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 25/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 26/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 27/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 28/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 29/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 30/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 31/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 32/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 33/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 34/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 35/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 36/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 37/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 38/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 39/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 40/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 41/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 42/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 43/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 44/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 45/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 46/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 47/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 48/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 49/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 50/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 51/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 52/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 53/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 54/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 55/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 56/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 57/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 58/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 59/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 60/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 61/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 62/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 63/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 64/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 65/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 66/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 67/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 68/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 69/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 70/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 71/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 72/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 73/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 74/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 75/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 76/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 77/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 78/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 79/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 80/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 81/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 82/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 83/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 84/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 85/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 86/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 87/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 88/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 89/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 90/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 91/500\n",
      "18780/18780 [==============================] - 0s 3us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 92/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 93/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 94/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 95/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 96/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 97/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 98/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 99/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 100/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 101/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 102/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 103/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 104/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 105/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 106/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 107/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 108/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 109/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 110/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 111/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 112/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 113/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 114/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 115/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 116/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 117/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 118/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 119/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 120/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 121/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 122/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 123/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 124/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 125/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 126/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 127/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 128/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 129/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 130/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 131/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 132/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 133/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 134/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 135/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 136/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 137/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 138/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 139/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 140/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 141/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 142/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 143/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 144/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 145/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 146/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 147/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 148/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 150/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 151/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 152/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 153/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 154/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 155/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 156/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 157/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 158/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 159/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 160/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 161/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 162/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 163/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 164/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 165/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 166/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 167/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 168/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 169/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 170/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 171/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 172/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 173/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 174/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 175/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 176/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 177/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 178/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 179/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 180/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 181/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 182/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 183/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 184/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 185/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 186/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 187/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 188/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 189/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 190/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 191/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 192/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 193/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 194/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 195/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 196/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 197/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 198/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 199/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 200/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 201/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 202/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 203/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 204/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 205/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 206/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 207/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 208/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 209/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 210/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 211/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 212/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 213/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 214/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 215/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 216/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 217/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 218/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 219/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 220/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 221/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 222/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 223/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 224/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 225/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 226/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 227/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 228/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 229/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 230/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 231/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 232/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 233/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 234/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 235/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 236/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 237/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 238/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 239/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 240/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 241/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 242/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 243/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 244/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 245/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 246/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 247/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 248/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 249/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 250/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 251/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 252/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 253/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 254/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 255/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 256/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 257/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 258/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 259/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 260/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 261/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 262/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 263/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 264/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 265/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 266/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 267/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 268/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 269/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 270/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 271/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 272/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 273/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 274/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 275/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 276/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 277/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 278/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 279/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 280/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 281/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 282/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 283/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 284/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 285/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 286/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 287/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 288/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 289/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 290/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 291/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 292/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 293/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 294/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 295/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 296/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 297/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 298/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 299/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 300/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 301/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 302/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 303/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 304/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 305/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 306/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 307/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 308/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 309/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 310/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 311/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 312/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 313/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 314/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 315/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 316/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 317/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 318/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 319/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 320/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 321/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 322/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 323/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 324/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 325/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 326/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 327/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 328/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 329/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 330/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 331/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 332/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 333/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 334/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 335/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 336/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 337/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 338/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 339/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 340/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 341/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 342/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 343/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 344/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 345/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 346/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 347/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 348/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 349/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 350/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 351/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 352/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 353/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 354/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 355/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 356/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 357/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 358/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 359/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 360/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 361/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 362/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 363/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 364/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 365/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 366/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 367/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 368/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 369/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 370/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 371/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 372/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 373/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 374/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 375/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 376/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 377/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 378/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 379/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 380/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 381/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 382/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 383/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 384/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 385/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 386/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 387/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 388/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 389/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 390/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 391/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 392/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 393/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 394/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 395/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 396/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 397/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 398/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 399/500\n",
      "18780/18780 [==============================] - 0s 3us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 400/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 401/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 402/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 403/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 404/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 405/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 406/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 407/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 408/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 409/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 410/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 411/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 412/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 413/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 414/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 415/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 416/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 417/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 418/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 419/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 420/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 421/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 422/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 423/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 424/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 425/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 426/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 427/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 428/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 429/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 430/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 431/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 432/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 433/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 434/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 435/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 436/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 437/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 438/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 439/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 440/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 441/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 442/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 443/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 444/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 445/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 446/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 447/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 448/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 449/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 450/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 451/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 452/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 453/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 454/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 455/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 456/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 457/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 458/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 459/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 460/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 461/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 462/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 463/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 464/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 465/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 466/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 467/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 468/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 469/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 470/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 471/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 472/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 473/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 474/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 475/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 476/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 477/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 478/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 479/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 480/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 481/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 482/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 483/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 484/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 485/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 486/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 487/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 488/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 489/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 490/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 491/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 492/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 493/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 494/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 495/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 496/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 497/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 498/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 499/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 500/500\n",
      "18780/18780 [==============================] - 0s 2us/step - loss: 0.0046 - val_loss: 0.0047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a315f7668>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 500\n",
    "batch_size = 3000\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=16, kernel_size=3, activation='relu', input_shape=(n_timesteps,1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu',name=\"featureLayer\")) # 将模型变得平缓 \n",
    "model.add(Dense(1)) # 最终只预测一个y，所以让模型只输出一个值 \n",
    "model.compile(loss='mse', optimizer='adam') # 确定优化方式\n",
    "\n",
    "# fit network\n",
    "model.fit(x_1, y, epochs=epochs, validation_split=0.2,batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.1.3 Calculate last layer values as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build new feature model, define input and output layer\n",
    "featureModel= Model(inputs=model.input,outputs=model.get_layer(\"featureLayer\").output) # 提取feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make prediction\n",
    "featureMatrix = featureModel.predict(x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23476, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureMatrix.shape # 10位latened feature "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3.2 Product feature extraction based on CNN model with 2 features(\"return\",\"\\vol_change\")\n",
    "将模型变得复杂起来，传入return和volume change两个参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you will need to input <brew install graphviz> in the terminal to plot the graph\n",
      "Train on 16433 samples, validate on 7043 samples\n",
      "Epoch 1/500\n",
      "16433/16433 [==============================] - 1s 44us/step - loss: 0.0088 - val_loss: 0.0049\n",
      "Epoch 2/500\n",
      "16433/16433 [==============================] - 0s 14us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 3/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 4/500\n",
      "16433/16433 [==============================] - 0s 15us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 5/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 6/500\n",
      "16433/16433 [==============================] - 0s 14us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 7/500\n",
      "16433/16433 [==============================] - 0s 14us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 8/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 9/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 10/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 11/500\n",
      "16433/16433 [==============================] - 0s 14us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 12/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 13/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 14/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 15/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 16/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 17/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 18/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 19/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 20/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 21/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 22/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 23/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 24/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 25/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 26/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 27/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 28/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 29/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 30/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 31/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 32/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 33/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 34/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 35/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 36/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 37/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 38/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 39/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 40/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 41/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 42/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 43/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 44/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 45/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 46/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 47/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 48/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 49/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 50/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 51/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 52/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 53/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 54/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 55/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 56/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 57/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 58/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 59/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 60/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 61/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 62/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 63/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 64/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 65/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 66/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 67/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 68/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 69/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 70/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 71/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 72/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 73/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 74/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 75/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 76/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 77/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 78/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 79/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 80/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 81/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 82/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 83/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 84/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 85/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 86/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 87/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 88/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 89/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 90/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 91/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 92/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 93/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 94/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 95/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 96/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 97/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 98/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 99/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 100/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 101/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 102/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 103/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 104/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 105/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 106/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 107/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 108/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 109/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 110/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 111/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 112/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 113/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 114/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 115/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 116/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 117/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 118/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 119/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 120/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 121/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 122/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 123/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 124/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 125/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 126/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 127/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 128/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 129/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 130/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 131/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 132/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 133/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 134/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 135/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 136/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 137/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 138/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 139/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 140/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 141/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 142/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 143/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 144/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 145/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 146/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 147/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 148/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 149/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 150/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 151/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 152/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 153/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 154/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 155/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 156/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 157/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 158/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 159/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0038 - val_loss: 0.0051\n",
      "Epoch 160/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 161/500\n",
      "16433/16433 [==============================] - 0s 14us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 162/500\n",
      "16433/16433 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 163/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 164/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 165/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 166/500\n",
      "16433/16433 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 167/500\n",
      "16433/16433 [==============================] - 0s 14us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 168/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 169/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 170/500\n",
      "16433/16433 [==============================] - 0s 14us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 171/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 172/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 173/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 174/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 175/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0037 - val_loss: 0.0051\n",
      "Epoch 176/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 177/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 178/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 179/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 180/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 181/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 182/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 183/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 184/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 185/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 186/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 187/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 188/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 189/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 190/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 191/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 192/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 193/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 194/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 195/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 196/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 197/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 198/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0034 - val_loss: 0.0054\n",
      "Epoch 199/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 200/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 201/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 202/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 203/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 204/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 205/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 206/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 207/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 208/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 209/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 210/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 211/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 212/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 213/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 214/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 215/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0033 - val_loss: 0.0055\n",
      "Epoch 216/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 217/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 218/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 219/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 220/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 221/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 222/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0031 - val_loss: 0.0052\n",
      "Epoch 223/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 224/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0031 - val_loss: 0.0052\n",
      "Epoch 225/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 226/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 227/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0031 - val_loss: 0.0056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 229/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 230/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 231/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 232/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 233/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 234/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 235/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 236/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 237/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 238/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 239/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0030 - val_loss: 0.0055\n",
      "Epoch 240/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 241/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0030 - val_loss: 0.0055\n",
      "Epoch 242/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0030 - val_loss: 0.0055\n",
      "Epoch 243/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0029 - val_loss: 0.0056\n",
      "Epoch 244/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0029 - val_loss: 0.0054\n",
      "Epoch 245/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0029 - val_loss: 0.0054\n",
      "Epoch 246/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 247/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 248/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0030 - val_loss: 0.0058\n",
      "Epoch 249/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0030 - val_loss: 0.0055\n",
      "Epoch 250/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0029 - val_loss: 0.0054\n",
      "Epoch 251/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 252/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0029 - val_loss: 0.0056\n",
      "Epoch 253/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0029 - val_loss: 0.0057\n",
      "Epoch 254/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0029 - val_loss: 0.0056\n",
      "Epoch 255/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 256/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 257/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0028 - val_loss: 0.0057\n",
      "Epoch 258/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0028 - val_loss: 0.0055\n",
      "Epoch 259/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0028 - val_loss: 0.0055\n",
      "Epoch 260/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0028 - val_loss: 0.0055\n",
      "Epoch 261/500\n",
      "16433/16433 [==============================] - 0s 14us/step - loss: 0.0028 - val_loss: 0.0057\n",
      "Epoch 262/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0028 - val_loss: 0.0059\n",
      "Epoch 263/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0028 - val_loss: 0.0057\n",
      "Epoch 264/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0028 - val_loss: 0.0055\n",
      "Epoch 265/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0028 - val_loss: 0.0056\n",
      "Epoch 266/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0028 - val_loss: 0.0056\n",
      "Epoch 267/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0028 - val_loss: 0.0057\n",
      "Epoch 268/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0028 - val_loss: 0.0056\n",
      "Epoch 269/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0028 - val_loss: 0.0056\n",
      "Epoch 270/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0028 - val_loss: 0.0057\n",
      "Epoch 271/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 272/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 273/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0027 - val_loss: 0.0056\n",
      "Epoch 274/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 275/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0027 - val_loss: 0.0056\n",
      "Epoch 276/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 277/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0027 - val_loss: 0.0059\n",
      "Epoch 278/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0027 - val_loss: 0.0059\n",
      "Epoch 279/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0027 - val_loss: 0.0058\n",
      "Epoch 280/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0027 - val_loss: 0.0058\n",
      "Epoch 281/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0027 - val_loss: 0.0061\n",
      "Epoch 282/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0027 - val_loss: 0.0058\n",
      "Epoch 283/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 284/500\n",
      "16433/16433 [==============================] - 0s 14us/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 285/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0027 - val_loss: 0.0058\n",
      "Epoch 286/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0026 - val_loss: 0.0058\n",
      "Epoch 287/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 288/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0026 - val_loss: 0.0060\n",
      "Epoch 289/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 290/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0026 - val_loss: 0.0058\n",
      "Epoch 291/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0026 - val_loss: 0.0058\n",
      "Epoch 292/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0026 - val_loss: 0.0057\n",
      "Epoch 293/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0026 - val_loss: 0.0058\n",
      "Epoch 294/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 295/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0027 - val_loss: 0.0059\n",
      "Epoch 296/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 297/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0026 - val_loss: 0.0061\n",
      "Epoch 298/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0026 - val_loss: 0.0058\n",
      "Epoch 299/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0026 - val_loss: 0.0058\n",
      "Epoch 300/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0026 - val_loss: 0.0061\n",
      "Epoch 301/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0026 - val_loss: 0.0061\n",
      "Epoch 302/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 303/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0026 - val_loss: 0.0059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0025 - val_loss: 0.0059\n",
      "Epoch 305/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0025 - val_loss: 0.0058\n",
      "Epoch 306/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0025 - val_loss: 0.0058\n",
      "Epoch 307/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0025 - val_loss: 0.0059\n",
      "Epoch 308/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0025 - val_loss: 0.0059\n",
      "Epoch 309/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0025 - val_loss: 0.0060\n",
      "Epoch 310/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0025 - val_loss: 0.0059\n",
      "Epoch 311/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0025 - val_loss: 0.0061\n",
      "Epoch 312/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0025 - val_loss: 0.0059\n",
      "Epoch 313/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0025 - val_loss: 0.0060\n",
      "Epoch 314/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0025 - val_loss: 0.0059\n",
      "Epoch 315/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 316/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0059\n",
      "Epoch 317/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 318/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0059\n",
      "Epoch 319/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0061\n",
      "Epoch 320/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0059\n",
      "Epoch 321/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0025 - val_loss: 0.0059\n",
      "Epoch 322/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0025 - val_loss: 0.0062\n",
      "Epoch 323/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0025 - val_loss: 0.0065\n",
      "Epoch 324/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0025 - val_loss: 0.0059\n",
      "Epoch 325/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0025 - val_loss: 0.0059\n",
      "Epoch 326/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0025 - val_loss: 0.0059\n",
      "Epoch 327/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 328/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 329/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 330/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 331/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0061\n",
      "Epoch 332/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0059\n",
      "Epoch 333/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 334/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 335/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 336/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 337/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0061\n",
      "Epoch 338/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0063\n",
      "Epoch 339/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0064\n",
      "Epoch 340/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0065\n",
      "Epoch 341/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0061\n",
      "Epoch 342/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 343/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 344/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 0.0061\n",
      "Epoch 345/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 346/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0061\n",
      "Epoch 347/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 348/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0066\n",
      "Epoch 349/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0063\n",
      "Epoch 350/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 0.0066\n",
      "Epoch 351/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 352/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0025 - val_loss: 0.0062\n",
      "Epoch 353/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 354/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 0.0063\n",
      "Epoch 355/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 0.0065\n",
      "Epoch 356/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 357/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 0.0063\n",
      "Epoch 358/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 359/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 360/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 0.0061\n",
      "Epoch 361/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 0.0060\n",
      "Epoch 362/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 0.0063\n",
      "Epoch 363/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0062\n",
      "Epoch 364/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0063\n",
      "Epoch 365/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0062\n",
      "Epoch 366/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0062\n",
      "Epoch 367/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 368/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0062\n",
      "Epoch 369/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 0.0064\n",
      "Epoch 370/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 371/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 0.0065\n",
      "Epoch 372/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 0.0066\n",
      "Epoch 373/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 0.0067\n",
      "Epoch 374/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 375/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 376/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 377/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0066\n",
      "Epoch 378/500\n",
      "16433/16433 [==============================] - 0s 14us/step - loss: 0.0022 - val_loss: 0.0064\n",
      "Epoch 379/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0063\n",
      "Epoch 381/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0062\n",
      "Epoch 382/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0064\n",
      "Epoch 383/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0062\n",
      "Epoch 384/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 385/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 386/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 387/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0021 - val_loss: 0.0063\n",
      "Epoch 388/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0021 - val_loss: 0.0063\n",
      "Epoch 389/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 390/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 391/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0021 - val_loss: 0.0066\n",
      "Epoch 392/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 393/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 394/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0021 - val_loss: 0.0066\n",
      "Epoch 395/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 396/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 397/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0021 - val_loss: 0.0067\n",
      "Epoch 398/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 399/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 400/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0066\n",
      "Epoch 401/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0021 - val_loss: 0.0066\n",
      "Epoch 402/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 403/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0068\n",
      "Epoch 404/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0071\n",
      "Epoch 405/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0070\n",
      "Epoch 406/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0070\n",
      "Epoch 407/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0067\n",
      "Epoch 408/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 409/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0063\n",
      "Epoch 410/500\n",
      "16433/16433 [==============================] - 0s 14us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 411/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 412/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 413/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0066\n",
      "Epoch 414/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 415/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0066\n",
      "Epoch 416/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 417/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 418/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 419/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 420/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 421/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0066\n",
      "Epoch 422/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 423/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0065\n",
      "Epoch 424/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 425/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0063\n",
      "Epoch 426/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 0.0064\n",
      "Epoch 427/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0068\n",
      "Epoch 428/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0068\n",
      "Epoch 429/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 430/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0065\n",
      "Epoch 431/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 432/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 433/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0069\n",
      "Epoch 434/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0068\n",
      "Epoch 435/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0067\n",
      "Epoch 436/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0067\n",
      "Epoch 437/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0071\n",
      "Epoch 438/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0067\n",
      "Epoch 439/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0067\n",
      "Epoch 440/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0068\n",
      "Epoch 441/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0069\n",
      "Epoch 442/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0069\n",
      "Epoch 443/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 444/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0067\n",
      "Epoch 445/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0067\n",
      "Epoch 446/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 447/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0070\n",
      "Epoch 448/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0071\n",
      "Epoch 449/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0069\n",
      "Epoch 450/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 451/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0067\n",
      "Epoch 452/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0066\n",
      "Epoch 453/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0069\n",
      "Epoch 454/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0071\n",
      "Epoch 455/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0066\n",
      "Epoch 457/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 0.0066\n",
      "Epoch 458/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 0.0069\n",
      "Epoch 459/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0069\n",
      "Epoch 460/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 461/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0067\n",
      "Epoch 462/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0071\n",
      "Epoch 463/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0072\n",
      "Epoch 464/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 0.0070\n",
      "Epoch 465/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 0.0072\n",
      "Epoch 466/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0070\n",
      "Epoch 467/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 0.0070\n",
      "Epoch 468/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0018 - val_loss: 0.0070\n",
      "Epoch 469/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0018 - val_loss: 0.0070\n",
      "Epoch 470/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0069\n",
      "Epoch 471/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0069\n",
      "Epoch 472/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0018 - val_loss: 0.0067\n",
      "Epoch 473/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 474/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0069\n",
      "Epoch 475/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0018 - val_loss: 0.0067\n",
      "Epoch 476/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 477/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0018 - val_loss: 0.0068\n",
      "Epoch 478/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0069\n",
      "Epoch 479/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0018 - val_loss: 0.0070\n",
      "Epoch 480/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0018 - val_loss: 0.0072\n",
      "Epoch 481/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0071\n",
      "Epoch 482/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0018 - val_loss: 0.0072\n",
      "Epoch 483/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0018 - val_loss: 0.0070\n",
      "Epoch 484/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0018 - val_loss: 0.0071\n",
      "Epoch 485/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0018 - val_loss: 0.0070\n",
      "Epoch 486/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0018 - val_loss: 0.0072\n",
      "Epoch 487/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0069\n",
      "Epoch 488/500\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 489/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0068\n",
      "Epoch 490/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0067\n",
      "Epoch 491/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0068\n",
      "Epoch 492/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0075\n",
      "Epoch 493/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0066\n",
      "Epoch 494/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 0.0067\n",
      "Epoch 495/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 0.0070\n",
      "Epoch 496/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 0.0072\n",
      "Epoch 497/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0018 - val_loss: 0.0068\n",
      "Epoch 498/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0018 - val_loss: 0.0069\n",
      "Epoch 499/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0018 - val_loss: 0.0069\n",
      "Epoch 500/500\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0018 - val_loss: 0.0070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a322b5630>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_layers, out_layers = list(), list()\n",
    "\n",
    "for i in range(n_features):\n",
    "    inputs = Input(shape=(n_timesteps,1))\n",
    "    conv1 = Conv1D(filters=32, kernel_size=3, activation='relu')(inputs)\n",
    "    conv2 = Conv1D(filters=32, kernel_size=3, activation='relu')(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(conv2)\n",
    "    flat = Flatten()(pool1)\n",
    "    # store layers\n",
    "    in_layers.append(inputs)\n",
    "    out_layers.append(flat)\n",
    "# merge heads\n",
    "merged = concatenate(out_layers)\n",
    "# interpretation\n",
    "dense1 = Dense(100, activation='relu')(merged)\n",
    "dense2 = Dense(10, activation='relu',name=\"featureLayer\")(dense1)\n",
    "\n",
    "outputs = Dense(n_outputs)(dense2)\n",
    "model = Model(inputs=in_layers, outputs=outputs)\n",
    "# compile model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# plot the model\n",
    "try:\n",
    "    plot_model(model, show_shapes=True, to_file='imgs/multiheaded_cnn.png')\n",
    "except:\n",
    "    print(\"you will need to input <brew install graphviz> in the terminal to plot the graph\")\n",
    "# fit network\n",
    "\n",
    "input_data = [x[:,:,i].reshape((x.shape[0],n_timesteps,1)) for i in range(n_features)]\n",
    "\n",
    "model.fit(x=input_data,y=y,validation_split=0.3,epochs=epochs,batch_size=batch_size,verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build new feature model, define input and output layer\n",
    "featureModel2= Model(inputs=in_layers,outputs=model.get_layer(\"featureLayer\").output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureMatrix2 = featureModel2.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23476, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureMatrix2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Modulize \n",
    "## Part 4.1 Modulize process part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class processor:\n",
    "    def cnn_process(self,df,rollSize=12):\n",
    "        if df.shape[0] < rollSize:\n",
    "            return None\n",
    "        else:\n",
    "            train_x = []\n",
    "            train_y = []\n",
    "            for i in range(df.shape[0]-rollSize):\n",
    "                x = df[['return','vol_change']].values[i:i+rollSize-1].tolist()  ### generate x\n",
    "                y = df['return'].values[i+rollSize]  ### generate y\n",
    "\n",
    "                train_x.append(x)\n",
    "                train_y.append([y])\n",
    "            return train_x,train_y\n",
    "\n",
    "    def generate_cnn_input(self,df):            \n",
    "        df_X_Y = df.groupby('Name').apply(lambda x: self.cnn_process(x,rollSize=12))\n",
    "        raw_x = []\n",
    "        raw_y = []\n",
    "        ID_2_stock = {}\n",
    "        for ID in range(len(df_X_Y.values)):\n",
    "            if df_X_Y.values[ID]: ## not none\n",
    "                stock = df_X_Y.index.values[ID]\n",
    "                ID_2_stock.update({ID:stock})\n",
    "                stockData = df_X_Y[stock]\n",
    "                raw_x.append(stockData[0])\n",
    "                raw_y.append(stockData[1])\n",
    "        y = np.vstack(raw_y)\n",
    "        x = np.vstack(raw_x)\n",
    "        return x,y,ID_2_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "myProcessor = processor()\n",
    "x,y,ID_2_stock = myProcessor.generate_cnn_input(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.2 Modulize model part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.utils import plot_model\n",
    "\n",
    "class extractor:\n",
    "    def train(self,x,y,n_timesteps,n_features,verbose=1,batch_size=2000,epochs=500,n_outputs=1):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.n_timesteps = n_timesteps\n",
    "        self.n_features = n_features\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.n_outputs = n_outputs\n",
    "        if self.n_timesteps <= 6: \n",
    "            raise Exception(\"Need at least 6 timesteps, Conv & Pool layer will reduce dimension by (3-1) + (3-1) + 2 = 6, check model structure below \")\n",
    "        \n",
    "        self.build_model()\n",
    "        self.fit()\n",
    "        self.build_feature_model()\n",
    "        \n",
    "    def build_model(self):\n",
    "        in_layers, out_layers = list(), list()\n",
    "\n",
    "        for i in range(self.n_features):\n",
    "            inputs = Input(shape=(self.n_timesteps,1))\n",
    "            conv1 = Conv1D(filters=32, kernel_size=3, activation='relu')(inputs)\n",
    "            conv2 = Conv1D(filters=32, kernel_size=3, activation='relu')(conv1)\n",
    "            pool1 = MaxPooling1D(pool_size=2)(conv2)\n",
    "            flat = Flatten()(pool1)\n",
    "            # store layers\n",
    "            in_layers.append(inputs)\n",
    "            out_layers.append(flat)\n",
    "        # merge headss\n",
    "        merged = concatenate(out_layers)\n",
    "        # interpretation\n",
    "        dense1 = Dense(100, activation='relu')(merged)\n",
    "        dense2 = Dense(10, activation='relu',name=\"featureLayer\")(dense1)\n",
    "\n",
    "        outputs = Dense(self.n_outputs)(dense2)\n",
    "        self.model = Model(inputs=in_layers, outputs=outputs)\n",
    "        # compile model\n",
    "        self.model.compile(loss='mse', optimizer='adam')\n",
    "        # plot the model\n",
    "        try:\n",
    "            plot_model(self.model, show_shapes=True, to_file='imgs/multiheaded_cnn.png')\n",
    "        except:\n",
    "            print(\"you will need to input <brew install graphviz> in the terminal to plot the graph\")\n",
    "        # fit network\n",
    "\n",
    "    def fit(self):\n",
    "        self.input_data = [self.x[:,:,i].reshape((self.x.shape[0],self.n_timesteps,1)) for i in range(self.n_features)]\n",
    "\n",
    "        self.model.fit(x=self.input_data,y=self.y,validation_split=0.3,epochs=self.epochs,batch_size=self.batch_size,verbose=self.verbose)\n",
    "    \n",
    "    def build_feature_model(self):\n",
    "        self.featureModel = Model(inputs=self.model.input,outputs=self.model.get_layer(\"featureLayer\").output)\n",
    "        \n",
    "    def get_feature_matrix(self,x):\n",
    "        input_data = [x[:,:,i].reshape((x.shape[0],self.n_timesteps,1)) for i in range(self.n_features)]\n",
    "\n",
    "        featureMatrix = self.featureModel.predict(input_data)\n",
    "        return featureMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you will need to input <brew install graphviz> in the terminal to plot the graph\n",
      "Train on 16433 samples, validate on 7043 samples\n",
      "Epoch 1/10\n",
      "16433/16433 [==============================] - 1s 48us/step - loss: 0.0064 - val_loss: 0.0047\n",
      "Epoch 2/10\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 3/10\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 4/10\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 5/10\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 6/10\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "16433/16433 [==============================] - 0s 15us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "16433/16433 [==============================] - 0s 13us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "16433/16433 [==============================] - 0s 12us/step - loss: 0.0052 - val_loss: 0.0045\n"
     ]
    }
   ],
   "source": [
    "myExtractor = extractor()\n",
    "myExtractor.train(x,y,n_timesteps=11,n_features=2,verbose=1,batch_size=2000,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name\n",
       "A       [[-0.021804511278195604, 0.30729241588489953],...\n",
       "AAL     [[0.10930506478209656, 0.4361392651433305], [0...\n",
       "AAP     [[0.07683848797250857, -0.4887237492222128], [...\n",
       "AAPL    [[-0.027209464161447428, 0.8220307265479732], ...\n",
       "ABBV    [[-0.033830539750884236, 0.4795471359833072], ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 给用户推荐产品一般都是用的产品最新的数据，所以从数据集中抽取最近11个月的return rate和vol_change\n",
    "recent_xs = df.groupby(\"Name\").apply(lambda x: x[['return','vol_change']][-11:].values) \n",
    "recent_xs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_x = []\n",
    "for stock in ID_2_stock.values():\n",
    "    recent_x.append(recent_xs[stock])\n",
    "recent_x = np.array(recent_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recent_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 11, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recent_x.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureMatrix = myExtractor.get_feature_matrix(recent_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.220275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1    2    3         4    5         6    7    8    9\n",
       "0    0.0  0.042652  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "1    0.0  0.117835  0.0  0.0  0.000000  0.0  0.019460  0.0  0.0  0.0\n",
       "2    0.0  0.018618  0.0  0.0  0.033598  0.0  0.079799  0.0  0.0  0.0\n",
       "3    0.0  0.082732  0.0  0.0  0.000000  0.0  0.040619  0.0  0.0  0.0\n",
       "4    0.0  0.059072  0.0  0.0  0.000000  0.0  0.003174  0.0  0.0  0.0\n",
       "5    0.0  0.088238  0.0  0.0  0.000000  0.0  0.008651  0.0  0.0  0.0\n",
       "6    0.0  0.099311  0.0  0.0  0.000000  0.0  0.061552  0.0  0.0  0.0\n",
       "7    0.0  0.091309  0.0  0.0  0.000000  0.0  0.007823  0.0  0.0  0.0\n",
       "8    0.0  0.035357  0.0  0.0  0.000000  0.0  0.014634  0.0  0.0  0.0\n",
       "9    0.0  0.220275  0.0  0.0  0.000000  0.0  0.118809  0.0  0.0  0.0\n",
       "10   0.0  0.095852  0.0  0.0  0.000000  0.0  0.004763  0.0  0.0  0.0\n",
       "11   0.0  0.096052  0.0  0.0  0.023700  0.0  0.000000  0.0  0.0  0.0\n",
       "12   0.0  0.072037  0.0  0.0  0.000000  0.0  0.048751  0.0  0.0  0.0\n",
       "13   0.0  0.042903  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "14   0.0  0.082521  0.0  0.0  0.000000  0.0  0.047252  0.0  0.0  0.0\n",
       "15   0.0  0.072347  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "16   0.0  0.039079  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "17   0.0  0.081682  0.0  0.0  0.000000  0.0  0.032461  0.0  0.0  0.0\n",
       "18   0.0  0.061380  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "19   0.0  0.092535  0.0  0.0  0.000000  0.0  0.068144  0.0  0.0  0.0\n",
       "20   0.0  0.095564  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "21   0.0  0.079710  0.0  0.0  0.000000  0.0  0.032256  0.0  0.0  0.0\n",
       "22   0.0  0.083443  0.0  0.0  0.000000  0.0  0.023961  0.0  0.0  0.0\n",
       "23   0.0  0.074356  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "24   0.0  0.096397  0.0  0.0  0.000000  0.0  0.017955  0.0  0.0  0.0\n",
       "25   0.0  0.074464  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "26   0.0  0.157890  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "27   0.0  0.027693  0.0  0.0  0.000000  0.0  0.099554  0.0  0.0  0.0\n",
       "28   0.0  0.104441  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "29   0.0  0.103495  0.0  0.0  0.000000  0.0  0.088757  0.0  0.0  0.0\n",
       "..   ...       ...  ...  ...       ...  ...       ...  ...  ...  ...\n",
       "470  0.0  0.107826  0.0  0.0  0.000000  0.0  0.082581  0.0  0.0  0.0\n",
       "471  0.0  0.065610  0.0  0.0  0.000000  0.0  0.023162  0.0  0.0  0.0\n",
       "472  0.0  0.082916  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "473  0.0  0.095941  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "474  0.0  0.011225  0.0  0.0  0.019828  0.0  0.051611  0.0  0.0  0.0\n",
       "475  0.0  0.031567  0.0  0.0  0.008717  0.0  0.000000  0.0  0.0  0.0\n",
       "476  0.0  0.087578  0.0  0.0  0.000000  0.0  0.001155  0.0  0.0  0.0\n",
       "477  0.0  0.082524  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "478  0.0  0.023433  0.0  0.0  0.000000  0.0  0.027213  0.0  0.0  0.0\n",
       "479  0.0  0.119976  0.0  0.0  0.000000  0.0  0.012827  0.0  0.0  0.0\n",
       "480  0.0  0.077416  0.0  0.0  0.000000  0.0  0.013232  0.0  0.0  0.0\n",
       "481  0.0  0.063610  0.0  0.0  0.000000  0.0  0.012662  0.0  0.0  0.0\n",
       "482  0.0  0.098487  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "483  0.0  0.109067  0.0  0.0  0.000000  0.0  0.030483  0.0  0.0  0.0\n",
       "484  0.0  0.107863  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "485  0.0  0.093159  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "486  0.0  0.087238  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "487  0.0  0.079458  0.0  0.0  0.000000  0.0  0.014813  0.0  0.0  0.0\n",
       "488  0.0  0.060576  0.0  0.0  0.013934  0.0  0.000000  0.0  0.0  0.0\n",
       "489  0.0  0.060293  0.0  0.0  0.000000  0.0  0.030521  0.0  0.0  0.0\n",
       "490  0.0  0.094272  0.0  0.0  0.002027  0.0  0.003633  0.0  0.0  0.0\n",
       "491  0.0  0.096570  0.0  0.0  0.000000  0.0  0.050124  0.0  0.0  0.0\n",
       "492  0.0  0.082523  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "493  0.0  0.090513  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "494  0.0  0.024205  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "495  0.0  0.093430  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "496  0.0  0.071257  0.0  0.0  0.000000  0.0  0.001164  0.0  0.0  0.0\n",
       "497  0.0  0.126980  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "498  0.0  0.054562  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0\n",
       "499  0.0  0.156233  0.0  0.0  0.000000  0.0  0.080788  0.0  0.0  0.0\n",
       "\n",
       "[500 rows x 10 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature matrix \n",
    "# 500支股票最近11个月的latend feature \n",
    "pd.DataFrame(featureMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(featureMatrix,\"/Users/heyifan/jupyter notebook/step5_featureMatrix\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
